{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+Uol4vUYUWXBUUBK88pDA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lookinsight/ml/blob/main/_20221109_ML_NaiveBayes(%EC%9E%90%EC%97%B0%EC%96%B4)_%EC%8A%A4%ED%8C%B8%EC%97%AC%EB%B6%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QUcTAAITD5vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns "
      ],
      "metadata": {
        "id": "ob9n7xVGCr4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/datasets/ucim/sms-spam-collection-dataset\n",
        "file_url = 'https://raw.githubusercontent.com/bigdata-young/bigdata_16th/main/data/spam.csv'\n",
        "df = pd.read_csv(file_url, index_col = 0) \n",
        "df.head()"
      ],
      "metadata": {
        "id": "3dnNkJ5wCr71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ii0MVrTeCr_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "id": "9J07MhcdCsCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.text.value_counts()"
      ],
      "metadata": {
        "id": "zuDaahNVFhmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text.nunique()"
      ],
      "metadata": {
        "id": "ljAEHMH7CsFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text.unique()"
      ],
      "metadata": {
        "id": "byaJjbN_CsJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 특수문자 제거"
      ],
      "metadata": {
        "id": "zmERHy30Joat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !#... (특수기호) 목록에서 제거해야할 - 영문\n",
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "id": "i-vde58gCsLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_text = df.text.loc[0] \n",
        "first_text      # 나중에 정규표현식 사용 방법도 공유"
      ],
      "metadata": {
        "id": "YfnxMXYhCsPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for v in first_text:\n",
        "    if v not in string.punctuation:\n",
        "        print(v) "
      ],
      "metadata": {
        "id": "kuiydZWTCsUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'r' in 'warrior', 'k' in 'warrior', 'k' not in 'warrior' "
      ],
      "metadata": {
        "id": "9LZq9aX5CsYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = [] \n",
        "for v in first_text:\n",
        "    if v not in string.punctuation:\n",
        "        new_text.append(v) \n",
        "new_text"
      ],
      "metadata": {
        "id": "OvuqYcVbCsbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join(new_text) "
      ],
      "metadata": {
        "id": "9o6ybFchCsec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(text: str) -> str:\n",
        "    new_text = [c for c in text if c not in string.punctuation]\n",
        "    return \"\".join(new_text)"
      ],
      "metadata": {
        "id": "b7aCPk9bHkkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_punc(df.text) "
      ],
      "metadata": {
        "id": "ZRHxWF_-Hknw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text.apply(remove_punc)"
      ],
      "metadata": {
        "id": "JbnWtLQTHksK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text = df['text'].apply(remove_punc) \n",
        "df.text"
      ],
      "metadata": {
        "id": "e6ByA6eFHkyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "8pTD61usJWlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords') "
      ],
      "metadata": {
        "id": "UjjqmFZqJWo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "lSCmUHXOJWsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english') "
      ],
      "metadata": {
        "id": "l33hoV5DJWxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_text = df.text.iloc[0]\n",
        "first_text"
      ],
      "metadata": {
        "id": "Q4n4M4aYJW0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 제거\n",
        "first_text.split() "
      ],
      "metadata": {
        "id": "C-Io875vJW2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_eng = stopwords.words('english') "
      ],
      "metadata": {
        "id": "KF0Q5d1TPsMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for word in first_text 는 안됨\n",
        "# 불용어 확인\n",
        "for word in first_text.split():\n",
        "    if word in stop_eng:\n",
        "        print(word) "
      ],
      "metadata": {
        "id": "vgbsOwkVJW6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 아닌 단어 출력\n",
        "for word in first_text.split():\n",
        "    if word not in stop_eng:\n",
        "        print(word) "
      ],
      "metadata": {
        "id": "MJIi8evdP7Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 아닌 단어 출력 - 소문자로 출력\n",
        "for word in first_text.split():\n",
        "    if word not in stop_eng:\n",
        "        print(word.lower()) "
      ],
      "metadata": {
        "id": "6j1K_G2DP7J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(text: str) -> str:\n",
        "    new_words = [] \n",
        "    for word in text.split():\n",
        "        if word not in stop_eng:\n",
        "            new_words.append(word.lower()) \n",
        "    return \" \".join(new_words) \n",
        "\n",
        "first_text, remove_stop_words(first_text) "
      ],
      "metadata": {
        "id": "ras82noWP7OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text = df.text.apply(remove_stop_words) \n",
        "df.text"
      ],
      "metadata": {
        "id": "aSBX0J01QPIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "prnnozYZQPLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJS9V5DqQPPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "knO6ulWFCshR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}