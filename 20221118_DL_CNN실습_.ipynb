{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMH/TuWFZa78QzEBVWPcAP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lookinsight/ml/blob/main/20221118_DL_CNN%EC%8B%A4%EC%8A%B5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpvGlW1YD_qR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 10가지 클래스를 갖는 이미지 데이터셋\n",
        "from torchvision.datasets.cifar import CIFAR10 \n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 불러오기\n",
        "training_data = CIFAR10(\n",
        "    root='./',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "test_data = CIFAR10(\n",
        "    root='./',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "jlKXWgHkHz3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls    # 리눅스 명령어 -> 파일들 뭐있는지 보여줌"
      ],
      "metadata": {
        "id": "LqbytCxwHz6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 데이터 보기 \n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1) \n",
        "    plt.imshow(training_data.data[i])\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7H-jtpxqHz-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 데이터 전처리 "
      ],
      "metadata": {
        "id": "yYj6dgd4Kryu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 증강 : 이미지에 여러 변형을 주어서 이미지 개수를 늘리는 방법 \n",
        "  - 회전, 크기 변경, 밀림, 반사, 이동\n",
        "  - 오버피팅 방지를 위해서 -> 이미지에 변화를 줘서 데이터 갯수를 늘리는 것 "
      ],
      "metadata": {
        "id": "4gRUXOhyLJP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 크롭핑 (Cropping)\n",
        "import matplotlib.pyplot as plt \n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torchvision.datasets.cifar import CIFAR10 \n",
        "from torchvision.transforms import Compose \n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomCrop  "
      ],
      "metadata": {
        "id": "PinBmnXvH0BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 어떤 순서대로 이미지 처리를 할 것인가\n",
        "transforms = Compose([ \n",
        "    T.ToPILImage(),\n",
        "    RandomCrop((32, 32), padding=4), # 랜덤으로 이미지를 일부 제거 하고 패딩\n",
        "    RandomHorizontalFlip(p=0.5), # y축으로 기준으로 대칭\n",
        "])"
      ],
      "metadata": {
        "id": "-qmUB6leH0Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = CIFAR10(\n",
        "    root='./',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "test_data = CIFAR10(\n",
        "    root='./',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "\n",
        "# 샘플 데이터 보기\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(transforms(training_data.data[i]))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rjVlwbiGH0KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 이미지 정규화\n",
        "from torchvision.transforms import Normalize\n",
        "\n",
        "transforms = Compose(\n",
        "    [\n",
        "        T.ToPILImage(),\n",
        "        RandomCrop((32, 32), padding=4), # 랜덤으로 이미지를 일부 제거 하고 패딩\n",
        "        RandomHorizontalFlip(p=0.5), # y축으로 기준으로 대칭\n",
        "        T.ToTensor(),\n",
        "        # 정규화 - mean (평균값) / std (표준편차) \n",
        "        # R(빨강), G(녹색), B(파랑)\n",
        "        Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261)),\n",
        "        T.ToPILImage(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "training_data = CIFAR10(\n",
        "    root='./',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "\n",
        "test_data = CIFAR10(\n",
        "    root='./',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "\n",
        "# 샘플 데이터 보기\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(transforms(training_data.data[i]))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z8M0gu2BH0NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 이미지 데이터셋의 평균, 표준편차 \n",
        "training_data = CIFAR10(\n",
        "    root='./',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# 0: 이미지 / 1: 분류에서 정답(레이블) \n",
        "imgs = [item[0] for item in training_data] # 이미지 > R,G,B 색상의 겹쳐저 있음\n",
        "imgs = torch.stack(imgs, dim = 0).numpy()  # 파이토치가 받아들일 수 있는 형태(3, H, W) "
      ],
      "metadata": {
        "id": "flcZBP7wH0Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs1 = [item[0] for item in training_data]\n",
        "print(len(imgs1))\n",
        "# 텐서는 요소의 모양을 중요하게 생각하기 때문에 텐서 안에 들어 있는 모든 요소의 모양이 동일해야만 함\n",
        "# torch.stack() -> (3, H, W) 요소의 모양을 고려하여 합치기\n",
        "imgs2 = torch.stack(imgs1, dim=0).numpy()\n",
        "# RGB, H(세로), W(가로)\n",
        "imgs2.shape"
      ],
      "metadata": {
        "id": "b0AoovzgEZ3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs[:,0,:,:]"
      ],
      "metadata": {
        "id": "iD70luK6PFzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_r = imgs[:,0,:,:].mean()   # 색상값 -> 평균 (mean)\n",
        "mean_g = imgs[:,1,:,:].mean()\n",
        "mean_b = imgs[:,2,:,:].mean()\n",
        "print(mean_r, mean_g, mean_b)"
      ],
      "metadata": {
        "id": "bEn5_xuhPGth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_r = imgs[:,0,:,:].std()   # 표준편차 -> std()\n",
        "std_g = imgs[:,1,:,:].std()\n",
        "std_b = imgs[:,2,:,:].std()\n",
        "print(std_r, std_g, std_b)"
      ],
      "metadata": {
        "id": "zoQ__D-UPGwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 정규화\n",
        "- 이미지는 R, G, B 데이터로 구성\n",
        "- 어떤 물체를 나태느냐에 따라 값이 편향\n",
        "- 데이터의 분포가 너무 치우쳐 있으면 학습에 안 좋은 영향 \n",
        "→ 따라서 학습하기 전 이런 편향을 계산에 최대한 정규분포를 따르게 하는 것이 좋음 (색이 갖는 분포가 일정하게 처리)\n",
        "⇒ 이 과정이 **정규화**"
      ],
      "metadata": {
        "id": "8F8mVlCIE5yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 정의 "
      ],
      "metadata": {
        "id": "v6on8_naV7X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.Sequential** -> 클래스 \n",
        ": 순서대로 층을 쌓아서 모델 구축 -> 커스터마이징 X \n",
        "* `간단한 신경망 구축`\n",
        "\n",
        "**nn.Module** : `복잡한 신경망`. 특징을 추출, 여러 가지 층을 추가  "
      ],
      "metadata": {
        "id": "2rhHAIVRV_kA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 루프 -> ( ) 블록\n",
        "\n",
        "입력 -> 합성곱 3 x 3 -> ReLU -> 합성곱 3x3 -> ReLU -> 맥스풀링(최댓값) -> 출력 "
      ],
      "metadata": {
        "id": "2oDjdr8cWwRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG 기본 블록 정의\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "G5v7kXhyPGzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Bird:\n",
        "#     def tweet(self):\n",
        "#         print('짹짹') \n",
        "\n",
        "# Bird().tweet()\n",
        "\n",
        "class Dog:\n",
        "    def __init__(self):\n",
        "        print('짹짹') \n",
        "\n",
        "Dog()"
      ],
      "metadata": {
        "id": "KgG3nIw5XhNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Person:\n",
        "    def __init__(self, name):\n",
        "        print(f'안녕하세요. 저는 {name} 입니다. ')\n",
        "\n",
        "Person('민') "
      ],
      "metadata": {
        "id": "KHWv0V-DYuPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Teacher(Person):\n",
        "    def __init__(self, name, subject): \n",
        "        super(Teacher, self).__init__(name) \n",
        "        print(f'저는 {subject}을(를) rkfmclqslek') \n",
        "\n",
        "Teacher(name = '박강사', subject = '코딩')"
      ],
      "metadata": {
        "id": "nscc36-fZVup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scikit? -> Model. 비슷한 함수, 비슷한 변수들...\n",
        "# 같은 포맷을 받아서 -> 그 안에 활용\n",
        "class BasicBlock(nn.Module):\n",
        "    # 기본 블록 구성하는 기본 정의\n",
        "    def __init__(self, in_channels, out_channels, hidden_dim):\n",
        "        # nn.Module\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # 합성곱 층\n",
        "        # in_channels : 입력 채널 수\n",
        "        # out_channels : 출력 채널 수\n",
        "        # hidden_dim : 은닉층 채널(차원) 수\n",
        "        # kernel_size : 커널의 크기\n",
        "        # padding : 이미지 외곽을 둘러쌀 0의 개수\n",
        "        # * * * <-  a x a   0 0 0 0 0\n",
        "        # * * *             0 * * * 0\n",
        "        # * * *             0 ......0\n",
        "        self.conv1 = nn.Conv2d(in_channels, hidden_dim,\n",
        "                               kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, out_channels,\n",
        "                               kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # 커널의 이동 거리 stride\n",
        "        # 2 * 2 <= 합성곱으로 처리된 값 [4칸] -> 최댓값\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    # 순전파 정의\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) # 합성곱1을 지나고\n",
        "        x = self.relu(x) # 활성화함수를 지나고\n",
        "        x = self.conv2(x) # 합성곱2를 지나고\n",
        "        x = self.relu(x) # 활성화함수\n",
        "        x = self.pool(x) # 맥스풀링을 지난걸\n",
        "        return x # 리턴"
      ],
      "metadata": {
        "id": "uXC4alF-V6RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최대 풀링 (Max Pooling)\n",
        "* 이미지 크기를 절반으로 줄이는 연산\n",
        "* 합성곱을 통해 얻은 특징의 위치 정보를 의도적으로 없애 오버피팅을 피하는 기법\n",
        "* 커널을 이동하면서 커널 안의 최댓값만을 남기는 것 → 중요한 특징의 값을 알 수 있음 (but 그 값의 위치는 알수 X)"
      ],
      "metadata": {
        "id": "-m6slNUKMXZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CNN 모델\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes): # 클래스 개수\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # 합성곱 기본 블록 정의\n",
        "        # 입력층 3개 -> R, G, B -> h, w (화소별) 입력층/츨력층 \n",
        "        # 32 x 32 -> 16.\n",
        "        self.block1 = BasicBlock(in_channels=3, out_channels=32, hidden_dim=16)\n",
        "        self.block2 = BasicBlock(in_channels=32, out_channels=128, hidden_dim=64)\n",
        "        self.block3 = BasicBlock(in_channels=128, out_channels=256, hidden_dim=128)\n",
        "        # 256.\n",
        "\n",
        "        # 분류기\n",
        "        self.fc1 = nn.Linear(in_features=4096, out_features=2048) # 데이터 손실 (4096 -> 10) \n",
        "        self.fc2 = nn.Linear(in_features=2048, out_features=256)\n",
        "        self.fc3 = nn.Linear(in_features=256, out_features=num_classes) # 10\n",
        "\n",
        "        # 분류기의 활성화 함수\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):  # 순전파를 했을 때 작동할 프로그램/기능\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x) # 출력 모양 (-1, 256, 4, 4) # h 4, w 4\n",
        "        x = torch.flatten(x, start_dim=1) # 256 x 4 x 4 = 4096\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "sxWQQX4ZV6UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "transforms = Compose([\n",
        "    RandomCrop((32, 32), padding=4), # 랜덤 크롭핑\n",
        "    RandomHorizontalFlip(p=0.5), # 1/2 확률로 y축 뒤집기\n",
        "    ToTensor(), # 텐서 변환\n",
        "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
        "])"
      ],
      "metadata": {
        "id": "FYaGNHBAV6Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용/평가용 데이터 불러오기\n",
        "training_data = CIFAR10(root='./', train=True, download=True, transform=transforms)\n",
        "test_data = CIFAR10(root='./', train=False, download=True, transform=transforms)\n",
        "\n",
        "# 데이터로더 정의 (batch size)\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# device? GPU(cuda)? CPU?\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# CNN 모델 정의 (<= CNN 클래스 불러오기 -> 객체)\n",
        "model = CNN(num_classes=10)\n",
        "\n",
        "# 모델을 device\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "iYPfCWsTV6ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3   # 학습률 정의 \n",
        "\n",
        "# 최적화 기법 정의 (adam) \n",
        "optim = Adam(model.parameters(), lr = lr) \n",
        "\n",
        "# 학습 루프 정의 \n",
        "for epoch in range(100): \n",
        "    for data , label in train_loader:   # 데이터 호출  \n",
        "        optim.zero_grad()     # 기울기 초기화 \n",
        "        preds = model(data.to(device)) \n",
        "\n",
        "        # 분류 문제 (회귀 문제면 MSE) \n",
        "        loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "        loss.backward()  # 오차 역전파\n",
        "        optim.step()   # 최적화       \n",
        "\n",
        "    if epoch == 0 or epoch % 10 == 9:\n",
        "        print(f'epoch{epoch + 1} loss:{loss.item()}') \n",
        "\n",
        "torch.save(model.state_dict(), 'CIFAR.pth') "
      ],
      "metadata": {
        "id": "cTp-YzmyV6hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('CIFAR.pth', map_location=device))\n",
        "\n",
        "num_corr = 0 \n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        output = model(data.to(device)) \n",
        "        preds = output.data.max(1)[1] \n",
        "        corr = preds.eq(label.to(device).data).sum().item() \n",
        "        num_corr += corr\n",
        "\n",
        "    print(f'Accuracy: {num_corr/len(test_data)}') "
      ],
      "metadata": {
        "id": "n3ggbkFxPG2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전이학습 모델 VGG 로 분류하기 \n",
        "# ImageNet: 1천개 사물에 대한 특징을 추출하도록 학습 \n",
        "# -> 사전 학습 -> 우리 데이터 넣어서 -> 10개의 학습 하도록 줄여서 -> 모델링 \n",
        "from torchvision.models.vgg import vgg16"
      ],
      "metadata": {
        "id": "sr-Z2dddPG5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = vgg16(pretrained=True)\n",
        "# 분류기 <- vgg16 이미 학습된 데이터를 통해 만들어진 모델\n",
        "# 10개를 분류 <- 커스터마이징\n",
        "# 분류기만 우리한테 맞도록 \n",
        "fc = nn.Sequential(\n",
        "    nn.Linear(512 * 7 * 7, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(), # 오버피팅\n",
        "    nn.Linear(4096, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(4096, 10),\n",
        ")\n",
        "\n",
        "model.classifier = fc\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "LxAv33D_H0T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리, 증강 \n",
        "# 데이터 로더 정의\n",
        "# 학습루프 정의\n",
        "# 모델 성능 평가\n",
        "\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "transforms = Compose([\n",
        "    # 전이학습한 모델 224\n",
        "    Resize(224),\n",
        "    RandomCrop((224, 224), padding=4), # 랜덤 크롭핑\n",
        "    RandomHorizontalFlip(p=0.5), # 1/2 확률로 y축 뒤집기\n",
        "    ToTensor(), # 텐서 변환\n",
        "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "# 학습용/평가용 데이터 불러오기\n",
        "training_data = CIFAR10(root='./', train=True, download=True, transform=transforms)\n",
        "test_data = CIFAR10(root='./', train=False, download=True, transform=transforms)\n",
        "\n",
        "# 데이터로더 정의 (batch size)\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "lr = 1e-4 # 학습률 정의\n",
        "\n",
        "# 최적화 기법 정의 (adam)\n",
        "optim = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "import tqdm\n",
        "\n",
        "# 학습 루프 정의\n",
        "for epoch in range(30):\n",
        "    iterator = tqdm.tqdm(train_loader)\n",
        "    for data, label in iterator: # 데이터 호출\n",
        "        optim.zero_grad() # 기울기 초기화\n",
        "        preds = model(data.to(device))\n",
        "        # 분류 문제 (회귀 문제면 MSE)\n",
        "        loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "        loss.backward() # 오차 역전파\n",
        "        optim.step() # 최적화\n",
        "    \n",
        "    if epoch==0 or epoch%10==9:\n",
        "        print(f\"epoch{epoch+1} loss:{loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"CIFAR_pretrained.pth\")"
      ],
      "metadata": {
        "id": "XzmA7HGyH0W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('CIFAR_pretrained.pth', map_location=device))\n",
        "\n",
        "num_corr = 0 \n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        output = model(data.to(device)) \n",
        "        preds = output.data.max(1)[1] \n",
        "        corr = preds.eq(label.to(device).data).sum().item() \n",
        "        num_corr += corr\n",
        "\n",
        "    print(f'Accuracy: {num_corr/len(test_data)}') "
      ],
      "metadata": {
        "id": "rTxue5eUH0ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qKcw7tcH0d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zivjxF-KH0gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tYMUnjk4H0jk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}